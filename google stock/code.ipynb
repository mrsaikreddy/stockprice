{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7137446,"sourceType":"datasetVersion","datasetId":4118797}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-19T10:21:47.548628Z","iopub.execute_input":"2023-12-19T10:21:47.549053Z","iopub.status.idle":"2023-12-19T10:21:47.558003Z","shell.execute_reply.started":"2023-12-19T10:21:47.549019Z","shell.execute_reply":"2023-12-19T10:21:47.556841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Load the dataset\ndata = pd.read_csv('/kaggle/input/google-stock-price/GOOG.csv')\n\n# Use only the 'Close' column for prediction\nclose_prices = data['Close'].values.reshape(-1, 1)\n\n# Normalize the data\nscaler = MinMaxScaler(feature_range=(0, 1))\nscaled_data = scaler.fit_transform(close_prices)\n\n# Create sequences for training\ndef create_sequences(data, time_step=60):\n    X, y = [], []\n    for i in range(len(data) - time_step - 1):\n        X.append(data[i:(i + time_step), 0])\n        y.append(data[i + time_step, 0])\n    return np.array(X), np.array(y)\n\ntime_step = 60\nX, y = create_sequences(scaled_data, time_step)\n\n# Splitting dataset into training and testing sets\ntrain_size = int(len(X) * 0.8)\nX_train, X_test = X[:train_size], X[train_size:]\ny_train, y_test = y[:train_size], y[train_size:]\n\n# Reshape input for LSTM [samples, time steps, features]\nX_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\nX_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-19T10:21:47.563851Z","iopub.execute_input":"2023-12-19T10:21:47.564259Z","iopub.status.idle":"2023-12-19T10:21:47.626720Z","shell.execute_reply.started":"2023-12-19T10:21:47.564228Z","shell.execute_reply":"2023-12-19T10:21:47.625419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\n\n# Build the LSTM model\nmodel = Sequential()\nmodel.add(LSTM(units=50, return_sequences=True, input_shape=(time_step, 1)))\nmodel.add(LSTM(units=50, return_sequences=False))\nmodel.add(Dense(1))\n\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-19T10:21:47.629270Z","iopub.execute_input":"2023-12-19T10:21:47.629974Z","iopub.status.idle":"2023-12-19T10:22:03.546019Z","shell.execute_reply.started":"2023-12-19T10:21:47.629932Z","shell.execute_reply":"2023-12-19T10:22:03.544741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\nmodel.fit(X_train, y_train, batch_size=32, epochs=10)\n# Predicting and Inversing the scaling\npredictions = model.predict(X_test)\npredictions = scaler.inverse_transform(predictions)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-19T10:22:03.547655Z","iopub.execute_input":"2023-12-19T10:22:03.548034Z","iopub.status.idle":"2023-12-19T10:23:31.133699Z","shell.execute_reply.started":"2023-12-19T10:22:03.547996Z","shell.execute_reply":"2023-12-19T10:23:31.132490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate RMSE for evaluation\nfrom sklearn.metrics import mean_squared_error\n\nrmse = np.sqrt(mean_squared_error(y_test, predictions))\nprint(f\"Test RMSE: {rmse}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-19T10:23:31.135835Z","iopub.execute_input":"2023-12-19T10:23:31.136217Z","iopub.status.idle":"2023-12-19T10:23:31.252939Z","shell.execute_reply.started":"2023-12-19T10:23:31.136183Z","shell.execute_reply":"2023-12-19T10:23:31.251740Z"},"trusted":true},"execution_count":null,"outputs":[]}]}